{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "NVcl9F3PbveD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json"
      ],
      "metadata": {
        "id": "JPXHEfM4PoJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast"
      ],
      "metadata": {
        "id": "UlJ5Ywh9HvXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re  # Importando a biblioteca de expressões regulares"
      ],
      "metadata": {
        "id": "xev80lLQHvOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "doZcxlIAbl6h"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "Rk5UWxfAbsAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = \"Chave de acesso\""
      ],
      "metadata": {
        "id": "4M-ojuDobtzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregando a Base de dados"
      ],
      "metadata": {
        "id": "CvvJe_vqdW28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kSIfgCUXbxFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('caminho/base.csv')"
      ],
      "metadata": {
        "id": "CIfA2DyhrnJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "c468MHgYHyFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trocando os vaores da Classe por numeros"
      ],
      "metadata": {
        "id": "b5CcRaWWdgWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['classe'] = df['classe'].replace({'Negativo': -1, 'Positivo': 1, 'Neutro': 0})"
      ],
      "metadata": {
        "id": "AeXN0bR2sUJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.classe.value_counts())"
      ],
      "metadata": {
        "id": "b2s6hPzssVSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Craindo colunas ba base para guardar os resultados do GPT"
      ],
      "metadata": {
        "id": "5U-dYzXcdnqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['gptpt'] = ''"
      ],
      "metadata": {
        "id": "bB4m3B4HIF_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "5hJh6Kkdy8gP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['descricaoGptpt'] = ''"
      ],
      "metadata": {
        "id": "1UHM-vuLIGht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "hcWUxWbTy-2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['erro'] = ''"
      ],
      "metadata": {
        "id": "HjF2tNA6Ukys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "y0o_LvcFADvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enviando para o GPT fazer as classificações"
      ],
      "metadata": {
        "id": "qoaKmZq0drFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model):\n",
        "  try:\n",
        "    # formatar o prompt como uma mensagem de usuário para a API de chat\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # chamar a API de chat com o modelo especificado, as mensagens e a temperatura\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0\n",
        "    )\n",
        "    # retornar o conteúdo da resposta\n",
        "    return response.choices[0].message[\"content\"]\n",
        "  except Exception as e:\n",
        "        return \"erro\""
      ],
      "metadata": {
        "id": "MjWdMzBVRXuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Classifique as frases a seguir como 'positiva', 'negativa' ou 'neutra'. As frases podem conter sarcasmo, ironia ou polarity shift. As frases são tweets relacionados a bancos e companhias telefónicas. Por fim, explique como você chegou a essas conclusões. Retorne todas essas informações no formato de um objeto JSON: \"\\\n",
        "\"{ \"\\\n",
        "    \"'classe': 'classe', \"\\\n",
        "    \"'explicacao_modelo': 'string'\"\\\n",
        "\"}\"\\\n",
        "\"Exemplos:\"\\\n",
        "\"Exemplo 1: \"\\\n",
        "\"Frase: 'o Banco do Brasil é bom, mas não ter um caixa eletronico para fazer saques a qualquer hora é horrivel'\"\\\n",
        "\"JSON esperado:\"\\\n",
        "\"{\"\\\n",
        "\"    'classe': 'negativa',\"\\\n",
        "\"    'explicacao_modelo': 'Apesar do banco ser bom, ele não oferece um serviço de saque a qualquer momento o que tora a experiencia ruim. Isto é um caso de polarity shift.'\"\\\n",
        "\"}\"\\\n",
        "\"Exemplo 2:\"\\\n",
        "\"Frase: 'Meu celular está fora de área há muitos dias e só consigo me comunicar por e-mail.'\"\\\n",
        "\"JSON esperado:\"\\\n",
        "\"{\"\\\n",
        "\"    'classe': 'negativa',\"\\\n",
        "\"    'explicacao_modelo': 'A frase é classificada como negativa porque a impossibilidade de usar o celular para comunicação é um problema significativo.'\"\\\n",
        "\"}\"\\\n",
        "\"Exemplo 3:\"\\\n",
        "\"Frase: 'Graças ao ótimo serviço da Vivo, não consegui ficar até o final do evento.'\"\\\n",
        "\"JSON esperado:\"\\\n",
        "\"{\"\\\n",
        "\"    'classe': 'negativa',\"\\\n",
        "\"    'explicacao_modelo': 'A frase contém ironia na expressão 'ótimo serviço', já que a pessoa não conseguiu ficar até o final do evento devido ao serviço ruim.'\"\\\n",
        "\"}\"\\\n",
        "\"Exemplo 4:\"\\\n",
        "\"Frase: 'cobertura da oi é muito boa'\"\\\n",
        "\"JSON esperado:\"\\\n",
        "\"{\"\\\n",
        "\"    'classe': ‘positiva’,\"\\\n",
        "\"    'explicacao_modelo': 'A frase possui polaridade positiva pois que a cobertura da rede telefonica é muito boa.’\"\\\n",
        "\"}\"\\\n",
        "\"Exemplo 5:\"\\\n",
        "\"Frase: 'Vou ao banco sacar dinheiro'\"\\\n",
        "\"JSON esperado:\"\\\n",
        "\"{\"\\\n",
        "\"    'classe': ’neutra’,\"\\\n",
        "\"    'explicacao_modelo': ‘a frase indica a que a pessoa vai fazer um saque, ma snão indica se isso é bom ou ruim, logo a frase é neutra.’\"\\\n",
        "\"} \"\\\n",
        "\"Agora, classifique a frase fornecida e explique a classificação: \""
      ],
      "metadata": {
        "id": "22JanYzIQiQN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=\"gpt-3.5-turbo\"\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  try:\n",
        "        frase = row['tweet']\n",
        "\n",
        "        prompt_final = prompt + \"Classifique a frase: '\" + frase + \"' \"\\\n",
        "                \"JSON esperado:\"\\\n",
        "                \"{\" \\\n",
        "                   \"'classe': 'classe',\" \\\n",
        "                    \"'explicacao_modelo': 'string'\" \\\n",
        "                \"}\"\n",
        "\n",
        "        #print(prompt)\n",
        "\n",
        "        response = get_completion(prompt_final, model)\n",
        "\n",
        "        print(response)\n",
        "\n",
        "        response_dict = json.loads(response)\n",
        "\n",
        "        # Salve o sentimento na coluna correspondente\n",
        "        df.at[index, 'gptpt'] = response_dict['classe']\n",
        "        df.at[index, 'descricaoGptpt'] = response_dict['explicacao_modelo']\n",
        "\n",
        "        print(\"----------------------------------------------------------------------------------------------------------------------------------\")\n",
        "  except Exception as e:\n",
        "      df.at[index, 'erro'] = response"
      ],
      "metadata": {
        "id": "dFrdCNzAHj2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "T8i6URb4x1SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.erro.value_counts())"
      ],
      "metadata": {
        "id": "t0xuu6lax3OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando a base classificada"
      ],
      "metadata": {
        "id": "i2AIKskBdxwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('caminho/base.csv', index=False)"
      ],
      "metadata": {
        "id": "JpeGC9Pg-q4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.classe.value_counts())"
      ],
      "metadata": {
        "id": "UpKBGJV_0LGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.gptpt.value_counts())"
      ],
      "metadata": {
        "id": "4Ncj1WYa0N_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passando a rotulação do GPT para numeros"
      ],
      "metadata": {
        "id": "jQycL_IzeUTc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['gptpt'] = df['gptpt'].replace({'negativa': -1, 'positiva': 1, 'neutra':0})"
      ],
      "metadata": {
        "id": "F24B8J-30DN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.gptpt.value_counts())"
      ],
      "metadata": {
        "id": "nDhr84GK0YhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ouRPmVIb0Wv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apurando as métricas"
      ],
      "metadata": {
        "id": "EPB8R69HeVZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def metricas(classe, gpt):\n",
        "  # Calcular as métricas\n",
        "  accuracy = accuracy_score(classe, gpt)\n",
        "  precision = precision_score(classe, gpt, average='weighted')\n",
        "  recall = recall_score(classe, gpt, average='weighted')\n",
        "  f1 = f1_score(classe, gpt, average='weighted')\n",
        "  print(\"Accuracy:\", accuracy)\n",
        "  print(\"Precision:\", precision)\n",
        "  print(\"Recall:\", recall)\n",
        "  print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "id": "V8oMvfR12kjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metricas(df['classe'], df['gptpt'])"
      ],
      "metadata": {
        "id": "kKy7ESNc2qLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando uma base somente com as diferenças parar poder analisar"
      ],
      "metadata": {
        "id": "L1G1lU0Yeg2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_diff = df[df['classe'] != df['gptpt']]"
      ],
      "metadata": {
        "id": "Jle7HKYO0be0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diff.to_csv('caminho/base.csv', index=False)"
      ],
      "metadata": {
        "id": "TxaJ5YoD1gtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_diff"
      ],
      "metadata": {
        "id": "cdeXNQNh1mS8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}